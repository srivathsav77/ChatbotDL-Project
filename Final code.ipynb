{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "premium-taste",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T12:09:49.513080Z",
     "iopub.status.busy": "2021-06-09T12:09:49.511940Z",
     "iopub.status.idle": "2021-06-09T12:09:57.107763Z",
     "shell.execute_reply": "2021-06-09T12:09:57.107149Z"
    },
    "id": "C2VNBU748SzM",
    "outputId": "fa3f04d9-03c2-4d95-dcbb-9d776aa4dbe8",
    "papermill": {
     "duration": 8.045966,
     "end_time": "2021-06-09T12:09:57.107923",
     "exception": false,
     "start_time": "2021-06-09T12:09:49.061957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "import time\n",
    "import io\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cc33178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and load the pretrained bert model\n",
    "modelname = 'deepset/bert-base-cased-squad2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
    "bModel = BertForQuestionAnswering.from_pretrained(modelname)\n",
    "QAPipeline = pipeline('question-answering', model=bModel, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7db35a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the topic you want to chat about\n"
     ]
    }
   ],
   "source": [
    "#ask the user to input the topic they want to query about\n",
    "print(\"Enter the topic you want to chat about\")\n",
    "inputTopic = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7599a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the corresponding artcile file and store it as the context input to our models\n",
    "a_file = inputTopic + \".txt\"\n",
    "with open(a_file,  encoding=\"ISO-8859-1\") as f:\n",
    "    text = f.readlines()\n",
    "    context = ' '.join([str(item) for item in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ac0e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer() # initialize the lemmatizer. WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "\n",
    "context = context.lower()# converts to lowercase\n",
    "sentenceTokens = nltk.sent_tokenize(context)# converts to list of sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0f8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions to implement the lemmatization\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "punctuationDictionary = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(punctuationDictionary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a816720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function to implement the tf-idf plus cosine similarity model.\n",
    "#it checks for the similarity threshold and calls the pre-trained bert model if the similarity is below the threshold\n",
    "def response(userQuery):\n",
    "    botResponse=''\n",
    "    sentenceTokens.append(userQuery)\n",
    "    vectorizer = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    vectors = vectorizer.fit_transform(sentenceTokens)\n",
    "    similarity = cosine_similarity(vectors[-1], vectors)\n",
    "    index =similarity.argsort()[0][-2]\n",
    "    similarity = similarity.flatten()\n",
    "    similarity.sort()\n",
    "    result = similarity[-2]\n",
    "    if(result<0.6):\n",
    "        print(\"Please wait...\")\n",
    "        botResposne = bertLookup(userQuery, context)\n",
    "        return botResposne\n",
    "    else:\n",
    "        botResponse = botResponse+sentenceTokens[index]\n",
    "        return botResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08e32f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function to call the bert pipeline\n",
    "def bertLookup(userQuery, context):\n",
    "    ans = QAPipeline({\n",
    "    'question': userQuery,\n",
    "    'context': context\n",
    "    })\n",
    "    return ans['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebbc5b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is canada's national unemployment rate?\n",
      "Please wait...\n",
      "5.9%\n"
     ]
    }
   ],
   "source": [
    "#Run the bot iteratively until the user inputs 'Exit'\n",
    "flag=True\n",
    "while(flag==True):\n",
    "    userQuery = input()\n",
    "    userQuery=userQuery.lower()\n",
    "    if(userQuery!='exit'):\n",
    "        print(userQuery)\n",
    "        print(response(userQuery))\n",
    "        sentenceTokens.remove(userQuery)\n",
    "    else:\n",
    "        print(\"Thank you, bye!\")\n",
    "        flag=False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 275.412871,
   "end_time": "2021-06-09T12:10:55.644105",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-09T12:06:20.231234",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
